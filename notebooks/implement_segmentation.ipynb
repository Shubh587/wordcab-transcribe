{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import wget\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def resolve_diarization_cache_dir() -> Path:\n",
    "    \"\"\"\n",
    "    Utility method to get the cache directory for the diarization module.\n",
    "\n",
    "    Returns:\n",
    "        Path: The path to the cache directory.\n",
    "    \"\"\"\n",
    "    path = Path.joinpath(Path.home(), f\".cache/torch/diarization\")\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is from NVIDIA NeMo toolkit package `FilterbankFeaturesTA` class:\n",
    "# https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/asr/parts/preprocessing/features.py#L469\n",
    "class MelSpectrogramPreprocessor(nn.Module):\n",
    "    \"\"\"Mel Spectrogram extraction.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate: int = 16000,\n",
    "        window_size: float = 0.025,\n",
    "        window_stride: float = 0.01,\n",
    "        window: str = \"hann\",\n",
    "        normalize: str = \"per_feature\",\n",
    "        n_fft: int = None,\n",
    "        preemph: float = 0.97,\n",
    "        features: int = 64,\n",
    "        lowfreq: int = 0,\n",
    "        highfreq: int = None,\n",
    "        log=True,\n",
    "        log_zero_guard_type=\"add\",\n",
    "        log_zero_guard_value=2 ** -24,\n",
    "        dither=1e-5,\n",
    "        pad_to=16,\n",
    "        max_duration=16.7,\n",
    "        frame_splicing=1,\n",
    "        exact_pad=False,\n",
    "        pad_value=0,\n",
    "        mag_power=2.0,\n",
    "        use_grads=False,\n",
    "        rng=None,\n",
    "        nb_augmentation_prob=0.0,\n",
    "        nb_max_freq=4000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if exact_pad and n_window_stride % 2 == 1:\n",
    "            raise NotImplementedError(\n",
    "                f\"{self} received exact_pad == True, but hop_size was odd. If audio_length % hop_size == 0. Then the \"\n",
    "                \"returned spectrogram would not be of length audio_length // hop_size. Please use an even hop_size.\"\n",
    "            )\n",
    "\n",
    "        self.log_zero_guard_value = log_zero_guard_value\n",
    "\n",
    "        self.win_length = int(window_size * sample_rate)\n",
    "        self.hop_length = int(window_stride * sample_rate)\n",
    "        self.n_fft = n_fft or 2 ** math.ceil(math.log2(self.win_length))\n",
    "        self.stft_pad_amount = (self.n_fft - self.hop_length) // 2 if exact_pad else None\n",
    "\n",
    "        torch_windows = {\n",
    "            \"hann\": torch.hann_window,\n",
    "            \"hamming\": torch.hamming_window,\n",
    "            \"blackman\": torch.blackman_window,\n",
    "            \"bartlett\": torch.bartlett_window,\n",
    "            \"none\": None,\n",
    "        }\n",
    "        window_fn = torch_windows.get(window, None)\n",
    "        window_tensor = window_fn(self.win_length, periodic=False) if window_fn else None\n",
    "        self.register_buffer(\"window\", window_tensor)\n",
    "        self.stft = lambda x: torch.stft(\n",
    "            x,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            center=False if exact_pad else True,\n",
    "            window=self.window.to(dtype=torch.float),\n",
    "            return_complex=True,\n",
    "        )\n",
    "\n",
    "        self.normalize = normalize\n",
    "        self.log = log\n",
    "        self.dither = dither\n",
    "        self.frame_splicing = frame_splicing\n",
    "        self.nfilt = nfilt\n",
    "        self.preemph = preemph\n",
    "        self.pad_to = pad_to\n",
    "        highfreq = highfreq or sample_rate / 2\n",
    "\n",
    "        filterbanks = torch.tensor(\n",
    "            librosa.filters.mel(sr=sample_rate, n_fft=self.n_fft, n_mels=nfilt, fmin=lowfreq, fmax=highfreq),\n",
    "            dtype=torch.float,\n",
    "        ).unsqueeze(0)\n",
    "        self.register_buffer(\"fb\", filterbanks)\n",
    "\n",
    "        # Calculate maximum sequence length\n",
    "        max_length = self.get_seq_len(torch.tensor(max_duration * sample_rate, dtype=torch.float))\n",
    "        max_pad = pad_to - (max_length % pad_to) if pad_to > 0 else 0\n",
    "        self.max_length = max_length + max_pad\n",
    "        self.pad_value = pad_value\n",
    "        self.mag_power = mag_power\n",
    "\n",
    "        # We want to avoid taking the log of zero\n",
    "        # There are two options: either adding or clamping to a small value\n",
    "        if log_zero_guard_type not in [\"add\", \"clamp\"]:\n",
    "            raise ValueError(\n",
    "                f\"{self} received {log_zero_guard_type} for the \"\n",
    "                f\"log_zero_guard_type parameter. It must be either 'add' or \"\n",
    "                f\"'clamp'.\"\n",
    "            )\n",
    "\n",
    "        self.use_grads = use_grads\n",
    "        if not use_grads:\n",
    "            self.forward = torch.no_grad()(self.forward)\n",
    "        self._rng = random.Random() if rng is None else rng\n",
    "        self.nb_augmentation_prob = nb_augmentation_prob\n",
    "        if self.nb_augmentation_prob > 0.0:\n",
    "            if nb_max_freq >= sample_rate / 2:\n",
    "                self.nb_augmentation_prob = 0.0\n",
    "            else:\n",
    "                self._nb_max_fft_bin = int((nb_max_freq / sample_rate) * n_fft)\n",
    "\n",
    "        self.log_zero_guard_type = log_zero_guard_type\n",
    "\n",
    "    def log_zero_guard_value_fn(self, x):\n",
    "        if isinstance(self.log_zero_guard_value, str):\n",
    "            if self.log_zero_guard_value == \"tiny\":\n",
    "                return torch.finfo(x.dtype).tiny\n",
    "            elif self.log_zero_guard_value == \"eps\":\n",
    "                return torch.finfo(x.dtype).eps\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"{self} received {self.log_zero_guard_value} for the \"\n",
    "                    f\"log_zero_guard_type parameter. It must be either a \"\n",
    "                    f\"number, 'tiny', or 'eps'\"\n",
    "                )\n",
    "        else:\n",
    "            return self.log_zero_guard_value\n",
    "\n",
    "    def get_seq_len(self, seq_len):\n",
    "        # Assuming that center is True is stft_pad_amount = 0\n",
    "        pad_amount = self.stft_pad_amount * 2 if self.stft_pad_amount is not None else self.n_fft // 2 * 2\n",
    "        seq_len = torch.floor((seq_len + pad_amount - self.n_fft) / self.hop_length) + 1\n",
    "        return seq_len.to(dtype=torch.long)\n",
    "\n",
    "    @property\n",
    "    def filter_banks(self):\n",
    "        return self.fb\n",
    "\n",
    "    def forward(self, x, seq_len, linear_spec=False):\n",
    "        seq_len = self.get_seq_len(seq_len.float())\n",
    "\n",
    "        if self.stft_pad_amount is not None:\n",
    "            x = torch.nn.functional.pad(\n",
    "                x.unsqueeze(1), (self.stft_pad_amount, self.stft_pad_amount), \"reflect\"\n",
    "            ).squeeze(1)\n",
    "\n",
    "        # do preemphasis\n",
    "        if self.preemph is not None:\n",
    "            x = torch.cat((x[:, 0].unsqueeze(1), x[:, 1:] - self.preemph * x[:, :-1]), dim=1)\n",
    "\n",
    "        # disable autocast to get full range of stft values\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            x = self.stft(x)\n",
    "\n",
    "        # torch stft returns complex tensor (of shape [B,N,T]); so convert to magnitude\n",
    "        # guard is needed for sqrt if grads are passed through\n",
    "        guard = 0 if not self.use_grads else 1e-5\n",
    "        x = torch.view_as_real(x)\n",
    "        x = torch.sqrt(x.pow(2).sum(-1) + guard)\n",
    "\n",
    "        # get power spectrum\n",
    "        if self.mag_power != 1.0:\n",
    "            x = x.pow(self.mag_power)\n",
    "\n",
    "        # return plain spectrogram if required\n",
    "        if linear_spec:\n",
    "            return x, seq_len\n",
    "\n",
    "        # dot with filterbank energies\n",
    "        x = torch.matmul(self.fb.to(x.dtype), x)\n",
    "        # log features if required\n",
    "        if self.log:\n",
    "            if self.log_zero_guard_type == \"add\":\n",
    "                x = torch.log(x + self.log_zero_guard_value_fn(x))\n",
    "            elif self.log_zero_guard_type == \"clamp\":\n",
    "                x = torch.log(torch.clamp(x, min=self.log_zero_guard_value_fn(x)))\n",
    "            else:\n",
    "                raise ValueError(\"log_zero_guard_type was not understood\")\n",
    "\n",
    "        # frame splicing if required\n",
    "        if self.frame_splicing > 1:\n",
    "            x = splice_frames(x, self.frame_splicing)\n",
    "\n",
    "        # normalize if required\n",
    "        if self.normalize:\n",
    "            x, _, _ = normalize_batch(x, seq_len, normalize_type=self.normalize)\n",
    "\n",
    "        # mask to zero any values beyond seq_len in batch, pad to multiple of `pad_to` (for efficiency)\n",
    "        max_len = x.size(-1)\n",
    "        mask = torch.arange(max_len).to(x.device)\n",
    "        mask = mask.repeat(x.size(0), 1) >= seq_len.unsqueeze(1)\n",
    "        x = x.masked_fill(mask.unsqueeze(1).type(torch.bool).to(device=x.device), self.pad_value)\n",
    "        del mask\n",
    "        pad_to = self.pad_to\n",
    "\n",
    "        if pad_to == \"max\":\n",
    "            x = nn.functional.pad(x, (0, self.max_length - x.size(-1)), value=self.pad_value)\n",
    "        elif pad_to > 0:\n",
    "            pad_amt = x.size(-1) % pad_to\n",
    "            if pad_amt != 0:\n",
    "                x = nn.functional.pad(x, (0, pad_to - pad_amt), value=self.pad_value)\n",
    "    \n",
    "        return x, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from NVIDIA NeMo's EncDecSpeakerLabelModel\n",
    "# https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/asr/models/label_models.py#L67\n",
    "class EncDecSpeakerLabelModel:\n",
    "    \"\"\"The EncDecSpeakerLabelModel class encapsulates the encoder-decoder speaker label model.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"titanet_large\") -> None:\n",
    "        \"\"\"Initialize the EncDecSpeakerLabelModel class.\n",
    "\n",
    "        The EncDecSpeakerLabelModel class encapsulates the encoder-decoder speaker label model.\n",
    "        Only the \"titanet_large\" model is supported at the moment.\n",
    "        For more models: https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/asr/models/label_models.py#L59\n",
    "\n",
    "        Args:\n",
    "            model_name (str, optional): The name of the model to use. Defaults to \"titanet_large\".\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the model name is not supported.\n",
    "        \"\"\"\n",
    "        if model_name != \"titanet_large\":\n",
    "            raise ValueError(\n",
    "                f\"Unknown model name: {model_name}. Only 'titanet_large' is supported at the moment.\"\n",
    "            )\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.location_in_the_cloud = \"https://api.ngc.nvidia.com/v2/models/nvidia/nemo/titanet_large/versions/v1/files/titanet-l.nemo\"\n",
    "        self.cache_dir = Path.joinpath(resolve_diarization_cache_dir(), \"titanet-l\")\n",
    "        cache_subfolder = hashlib.md5((self.location_in_the_cloud).encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "        self.nemo_model_folder, self.nemo_model_file = self.download_model_if_required(\n",
    "            url=self.location_in_the_cloud, cache_dir=self.cache_dir, subfolder=cache_subfolder,\n",
    "        )\n",
    "\n",
    "        self.model_files = Path.joinpath(self.nemo_model_folder, \"model_files\")\n",
    "        if not self.model_files.exists():\n",
    "            self.model_files.mkdir(parents=True, exist_ok=True)\n",
    "            self.unpack_nemo_file(self.nemo_model_file, self.model_files)\n",
    "\n",
    "        model_weights_file_path = Path.joinpath(self.model_files, \"model_weights.ckpt\")\n",
    "        model_config_file_path = Path.joinpath(self.model_files, \"model_config.yaml\")\n",
    "        with open(model_config_file_path, \"r\") as config_file:\n",
    "            self.model_config = yaml.safe_load(config_file)\n",
    "        \n",
    "        self.preprocessor = EncDecSpeakerLabelModel.from_config_dict(cfg.preprocessor)\n",
    "        self.encoder = EncDecSpeakerLabelModel.from_config_dict(cfg.encoder)\n",
    "        self.decoder = EncDecSpeakerLabelModel.from_config_dict(cfg.decoder)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def download_model_if_required(url, subfolder=None, cache_dir=None) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Helper function to download pre-trained weights from the cloud.\n",
    "\n",
    "        Args:\n",
    "            url: (str) URL to download from.\n",
    "            cache_dir: (str) a cache directory where to download. If not present, this function will attempt to create it.\n",
    "                If None (default), then it will be $HOME/.cache/torch/diarization\n",
    "            subfolder: (str) subfolder within cache_dir. The file will be stored in cache_dir/subfolder. Subfolder can\n",
    "                be empty\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, str]: cache_dir and filepath to the downloaded file.\n",
    "        \"\"\"\n",
    "        destination = Path.joinpath(cache_dir, subfolder)\n",
    "\n",
    "        if not destination.exists():\n",
    "            destination.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        destination_file = Path.joinpath(destination, filename)\n",
    "\n",
    "        if destination_file.exists():\n",
    "            return destination, destination_file\n",
    "\n",
    "        i = 0\n",
    "        while i < 10:  # try 10 times\n",
    "            i += 1\n",
    "\n",
    "            try:\n",
    "                wget.download(url, str(destination_file))\n",
    "                if os.path.exists(destination_file):\n",
    "                    return destination, destination_file\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        raise ValueError(\"Not able to download the diarization model, please try again later.\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def unpack_nemo_file(filepath: Path, out_folder: Path) -> str:\n",
    "        \"\"\"\n",
    "        Unpacks a .nemo file into a folder.\n",
    "\n",
    "        Args:\n",
    "            filepath (Path): path to the .nemo file (can be compressed or uncompressed)\n",
    "            out_folder (Path): path to the folder where the .nemo file should be unpacked\n",
    "\n",
    "        Returns:\n",
    "            path to the unpacked folder\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tar = tarfile.open(filepath, \"r:\")  # try uncompressed\n",
    "        except tarfile.ReadError:\n",
    "            tar = tarfile.open(filepath, \"r:gz\")  # try compressed\n",
    "        finally:\n",
    "            tar.extractall(path=out_folder)\n",
    "            tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.core.classes.common import Serialization\n",
    "from omegaconf import DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncDecSpeakerLabelModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor',\n",
       " 'normalize': 'per_feature',\n",
       " 'window_size': 0.025,\n",
       " 'sample_rate': 16000,\n",
       " 'window_stride': 0.01,\n",
       " 'window': 'hann',\n",
       " 'features': 80,\n",
       " 'n_fft': 512,\n",
       " 'frame_splicing': 1,\n",
       " 'dither': 1e-05}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_config[\"preprocessor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
